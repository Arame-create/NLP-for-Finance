{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoWVx_KHwlOq"
      },
      "source": [
        "# __Group Assignment__\n",
        "\n",
        "__Submission Date:__ 26/03/2025\n",
        "\n",
        "__Assignment: NLP-2024-2025: Assignment 1__\n",
        "\n",
        "__Group Members:__\n",
        "- ANZALONE Gabriel\n",
        "- MBENGUE Ndèye Arame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn3nBFurwymC"
      },
      "source": [
        "__Firm level topic of discussion:__ Technological Disruption\n",
        "\n",
        "__Task__ : Measure <u>Technological Disruption</u> with transcripts of Conference Calls."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## __1- Constructing a measure related to <u> Technological Disruption</u> for each firm and each quarter.__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.A- Data Preparation and Text Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyarrow\n",
            "  Downloading pyarrow-19.0.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Downloading pyarrow-19.0.1-cp312-cp312-manylinux_2_28_x86_64.whl (42.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyarrow\n",
            "Successfully installed pyarrow-19.0.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Code for Github\n",
        "!pip install pyarrow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting nltk\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting click (from nltk)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: joblib in /home/codespace/.local/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
            "Collecting regex>=2021.8.3 (from nltk)\n",
            "  Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "Collecting tqdm (from nltk)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Installing collected packages: tqdm, regex, click, nltk\n",
            "Successfully installed click-8.1.8 nltk-3.9.1 regex-2024.11.6 tqdm-4.67.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Code for Github\n",
        "! pip install nltk\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoKcY7ouyUGg"
      },
      "source": [
        "- Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "dL1uhJxHyY47"
      },
      "outputs": [],
      "source": [
        "# Lets say that we just want to focus on the management presentation section of the Earnings Calls\n",
        "# We import Earnings Calls and Q&A sessions of S&P500 from 2015 to 2021\n",
        "\n",
        "import pandas as pd\n",
        "# Loading Earning calls \n",
        "Sample_EC = pd.read_csv(\"https://www.dropbox.com/scl/fi/2p7ahxroqj9pwf98ni5an/Sample_Calls.csv?rlkey=zfieicvz891u4e3z0aroeg0u7&dl=1\")\n",
        "\n",
        "# Loading Presentations\n",
        "Sample_Presentations = pd.read_feather(\"https://www.dropbox.com/scl/fi/uceh2xva5g4apbmt92cgt/Sample_Calls_Presentations.feather?rlkey=ln4nzsa4nenqyvm0pg2cur9sp&dl=1\")\n",
        "# Loading Q&As\n",
        "Sample_QAs = pd.read_feather(\"https://www.dropbox.com/scl/fi/iq4111nlmsykp2tzxk9xg/Sample_Calls_QA.feather?rlkey=xabjqmwhesx05jivrlfzkgj6m&dl=1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>presentation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...</td>\n",
              "      <td>Good day and welcome to the Linear Technol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...</td>\n",
              "      <td>Welcome to Cerner Corporation's first quar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...</td>\n",
              "      <td>Welcome to Cerner Corporation's second qua...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...</td>\n",
              "      <td>Welcome to Cerner Corporation's third quar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...</td>\n",
              "      <td>Welcome to Cerner Corporation's fourth qua...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           file_name  \\\n",
              "0  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...   \n",
              "1  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...   \n",
              "2  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...   \n",
              "3  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...   \n",
              "4  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...   \n",
              "\n",
              "                                        presentation  \n",
              "0      Good day and welcome to the Linear Technol...  \n",
              "1      Welcome to Cerner Corporation's first quar...  \n",
              "2      Welcome to Cerner Corporation's second qua...  \n",
              "3      Welcome to Cerner Corporation's third quar...  \n",
              "4      Welcome to Cerner Corporation's fourth qua...  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Sample_Presentations.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>QA</th>\n",
              "      <th>speaker_name</th>\n",
              "      <th>file_name</th>\n",
              "      <th>QA_text</th>\n",
              "      <th>QA_number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>q</td>\n",
              "      <td>david wong</td>\n",
              "      <td>Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...</td>\n",
              "      <td>Thanks very much. Don, could you give us some ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a</td>\n",
              "      <td>don zerio</td>\n",
              "      <td>Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...</td>\n",
              "      <td>Yes, David, as you know we retired our convert...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>q</td>\n",
              "      <td>david wong</td>\n",
              "      <td>Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...</td>\n",
              "      <td>Great, thanks.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>q</td>\n",
              "      <td>craig hettenbach</td>\n",
              "      <td>Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...</td>\n",
              "      <td>Great thank you. Just a question on the commen...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a</td>\n",
              "      <td>lothar maier</td>\n",
              "      <td>Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...</td>\n",
              "      <td>When you think about China you know, particula...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  QA       speaker_name                                          file_name  \\\n",
              "0  q         david wong  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...   \n",
              "1  a          don zerio  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...   \n",
              "2  q         david wong  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...   \n",
              "3  q   craig hettenbach  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...   \n",
              "4  a       lothar maier  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...   \n",
              "\n",
              "                                             QA_text  QA_number  \n",
              "0  Thanks very much. Don, could you give us some ...          1  \n",
              "1  Yes, David, as you know we retired our convert...          1  \n",
              "2                                     Great, thanks.          2  \n",
              "3  Great thank you. Just a question on the commen...          3  \n",
              "4  When you think about China you know, particula...          3  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Sample_QAs.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filtering for consistency\n",
        "Sample_QAs = Sample_QAs[\n",
        "    Sample_QAs['QA_text'].str.split().apply(len) > 50\n",
        "].reset_index(drop=True)\n",
        "\n",
        "Sample_Presentations = Sample_Presentations[\n",
        "    Sample_Presentations['presentation'].str.split().apply(len) > 50 # filter to keep presentations with at least 50 words\n",
        "].reset_index(drop=True)\n",
        "\n",
        "# Grouping by file_name and concatenating presentation column (concatenating all text belonging to the same call into one large text entry)\n",
        "Pres = Sample_Presentations.groupby(\"file_name\")[\"presentation\"].agg(lambda x: \" \".join(x)).reset_index()\n",
        "Pres.columns= [\"file_name\",\"text\"]\n",
        "\n",
        "QA = Sample_QAs.groupby(\"file_name\")[\"QA_text\"].agg(lambda x: \" \".join(x)).reset_index()\n",
        "QA.columns = [\"file_name\", \"text\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_HBmjz9dNpZ"
      },
      "source": [
        "- Prep-processing Textual Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJwMCdV7dMvQ",
        "outputId": "08771f50-11d2-440f-84b6-ce9d9c6002a0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/codespace/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/codespace/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     /home/codespace/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /home/codespace/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# librairies\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize #breaking text into words\n",
        "from nltk.stem import WordNetLemmatizer #reducing words to their base form\n",
        "\n",
        "# Downloading data \n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HcVD_UxWdUQX"
      },
      "outputs": [],
      "source": [
        "# We first tokenize words & remove the stopwords\n",
        "stop_words = set(stopwords.words('english')) # preprocessing all words, removing the stopwords and using tokenization\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower()) # putting all in lowercase format\n",
        "    tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
        "    return tokens\n",
        "\n",
        "Pres['tokens'] = Pres['text'].apply(preprocess_text)\n",
        "\n",
        "QA['tokens'] = QA['text'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "x9nq2CGndXw1"
      },
      "outputs": [],
      "source": [
        "# Then we lemmatize to have a unified format\n",
        "# Either use WordNetLemmatizer or Spacy -> better to use the latter to take the context of each word into account (POS Tagging)\n",
        "# But it is way Longer than WordNet to run\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(tokens):\n",
        "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "Pres['tokens'] = Pres['tokens'].apply(lemmatize_text)\n",
        "\n",
        "QA['tokens'] = QA['tokens'].apply(lemmatize_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "EVFT33D0eDHT",
        "outputId": "a56daeec-da7f-40c0-bad1-5e27486105f4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[lady, gentleman, thank, standing, welcome, fi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[welcome, prudential, quarterly, earnings, cal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[lady, gentleman, thank, standing, welcome, pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[lady, gentleman, thank, standing, welcome, q1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[lady, gentleman, thank, standing, welcome, q2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[thank, tom, good, morning, everyone, welcome,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[welcome, southwest, airline, second, quarter,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[thank, tom, good, morning, everyone, welcome,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[lady, gentleman, thank, standing, welcome, an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[lady, gentleman, thank, standing, welcome, an...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "0    [lady, gentleman, thank, standing, welcome, fi...\n",
              "1    [welcome, prudential, quarterly, earnings, cal...\n",
              "2    [lady, gentleman, thank, standing, welcome, pr...\n",
              "3    [lady, gentleman, thank, standing, welcome, q1...\n",
              "4    [lady, gentleman, thank, standing, welcome, q2...\n",
              "5    [thank, tom, good, morning, everyone, welcome,...\n",
              "6    [welcome, southwest, airline, second, quarter,...\n",
              "7    [thank, tom, good, morning, everyone, welcome,...\n",
              "8    [lady, gentleman, thank, standing, welcome, an...\n",
              "9    [lady, gentleman, thank, standing, welcome, an...\n",
              "Name: tokens, dtype: object"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Pres['tokens'].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'QA_text' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mQA_text\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'QA_text' is not defined"
          ]
        }
      ],
      "source": [
        "QA_text['tokens'].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yi7ePwBNeDDJ",
        "outputId": "3d65ebcd-858e-4b6e-fc6c-56e3152663eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Pres['text'].isnull().sum() # 0 null value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guhbcSWxBPbn"
      },
      "source": [
        "### 1 - Using Cosine Similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0smAxZ8LfeT"
      },
      "source": [
        "Working with Google Word2Vec API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9PIhejul30o"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip uninstall -y numpy gensim scipy smart-open\n",
        "!pip install numpy==1.25.2 scipy gensim smart-open\n",
        "# After this, restart session (don't delete runtime)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRw4d009-y16"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api\n",
        "google_model = api.load(\"word2vec-google-news-300\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ienyzD_-BaQw",
        "outputId": "a6a02fdb-3532-459f-df81-8cc38d6897ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('technological_advancement', 0.6745783090591431), ('technological_advances', 0.6342653036117554), ('technological_innovations', 0.6328529715538025), ('technologic', 0.6312510967254639), ('DISABILITY_RESOURCE_CENTER', 0.6264010667800903)]\n"
          ]
        }
      ],
      "source": [
        "# What we will do is select a bunch of words based on their similarity with Technological Disruption and add them to our tech dictionnary\n",
        "# First using: \"most_similar\" function of google_model\n",
        "# Limit = we can use only one word\n",
        "print(google_model.most_similar(\"technological\", topn=5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQUaut9iDGgW",
        "outputId": "6a801ae5-277a-45c5-9495-8ecfca16a063"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('disruptions', 0.8658042550086975), ('interruption', 0.658836841583252), ('interruptions', 0.6469897627830505), ('distruption', 0.6304445862770081), ('disrupted', 0.6218001842498779)]\n"
          ]
        }
      ],
      "source": [
        "print(google_model.most_similar(\"disruption\", topn=5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DLqImGCDTM_",
        "outputId": "3b4fecd8-03e9-49a9-d92b-5bd0f44e080a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('innovations', 0.7695900797843933), ('technological_advances', 0.7287052869796753), ('technological_advancements', 0.7118793725967407), ('technological_advancement', 0.6809303760528564), ('technologies', 0.6743346452713013)]\n"
          ]
        }
      ],
      "source": [
        "print(google_model.most_similar(\"technological_innovations\", topn=5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eqjmz1EuD6hp"
      },
      "outputs": [],
      "source": [
        "# Lets say we want to create a bag of words that are closely linked to technological disruption:\n",
        "# We can select among these and add our proper words to create a dictionnary:\n",
        "\n",
        "keywords = [\"disruption\",\"technological\",\"interruption\",\"advancement\",\"innovation\",\"ai\",\"automation\", \"robotics\", \"technology\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPU8LF3iMOtP"
      },
      "source": [
        "Computing Cosine Similarity mean of this vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXf1bmJrEYlI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# If we take the mean of all of these keywords in the model, and word with the cosine similarity:\n",
        "tech_vectors = np.mean([google_model[word] for word in keywords if word in google_model], axis=0)\n",
        "\n",
        "def compute_similarity(tokens):\n",
        "    vectors = np.array([google_model[word] for word in tokens if word in google_model])\n",
        "    if vectors.size == 0:\n",
        "        return 0  # Aucun mot trouvé dans le modèle\n",
        "    avg_vector = np.mean(vectors, axis=0)\n",
        "    similarity = cosine_similarity([avg_vector], [tech_vectors])[0][0]\n",
        "    return similarity\n",
        "\n",
        "Pres['tech_disruption_score'] = Pres['tokens'].apply(compute_similarity) # affecting a score to each"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tA70PcuzMrTb"
      },
      "source": [
        "Filtering Companies based on their score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FyW3GwX4Nz1x"
      },
      "outputs": [],
      "source": [
        "Pres = Pres.merge(Sample_EC[['file_name', 'co_conm']], on='file_name', how='left') # we merge the data to get the names of the companies\n",
        "\n",
        "sorted_pres = Pres.sort_values(by='tech_disruption_score', ascending=False) # filtering by the disruption score\n",
        "\n",
        "top_10 = sorted_pres[['file_name', 'co_conm', 'tech_disruption_score']].head(10)\n",
        "bottom_10 = sorted_pres[['file_name', 'co_conm', 'tech_disruption_score']].tail(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRzlGy2PRSf8",
        "outputId": "ae9c68ae-9721-4665-8a72-85c42208c96b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "These are the Top 10 companies related to Technological Disruption:\n",
            "                                              file_name  \\\n",
            "2557  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2020...   \n",
            "1948  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2019...   \n",
            "446   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...   \n",
            "2805  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2020...   \n",
            "2595  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2020...   \n",
            "695   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...   \n",
            "780   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...   \n",
            "1996  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2019...   \n",
            "1464  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2018...   \n",
            "510   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...   \n",
            "\n",
            "                       co_conm  tech_disruption_score  \n",
            "2557               NVIDIA CORP               0.597319  \n",
            "1948                 ANSYS INC               0.596867  \n",
            "446                NVIDIA CORP               0.591857  \n",
            "2805               NVIDIA CORP               0.588900  \n",
            "2595              SYNOPSYS INC               0.588518  \n",
            "695               SYNOPSYS INC               0.587765  \n",
            "780   COGNIZANT TECH SOLUTIONS               0.586810  \n",
            "1996               NVIDIA CORP               0.584074  \n",
            "1464               NVIDIA CORP               0.583366  \n",
            "510   COGNIZANT TECH SOLUTIONS               0.579628  \n",
            "\n",
            "These are the Bottom 10 companies related to Technological Disruption:\n",
            "                                              file_name           co_conm  \\\n",
            "23    Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...   ROSS STORES INC   \n",
            "2787  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2020...     CELANESE CORP   \n",
            "986   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...  WYNN RESORTS LTD   \n",
            "580   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...       NETFLIX INC   \n",
            "600   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...   ROSS STORES INC   \n",
            "1990  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2019...   ROSS STORES INC   \n",
            "1283  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2018...   ROSS STORES INC   \n",
            "1030  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...       NETFLIX INC   \n",
            "184   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...  WYNN RESORTS LTD   \n",
            "880   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...       NETFLIX INC   \n",
            "\n",
            "      tech_disruption_score  \n",
            "23                 0.333194  \n",
            "2787               0.332099  \n",
            "986                0.331706  \n",
            "580                0.328053  \n",
            "600                0.326975  \n",
            "1990               0.326335  \n",
            "1283               0.317994  \n",
            "1030               0.317884  \n",
            "184                0.313835  \n",
            "880                0.293479  \n"
          ]
        }
      ],
      "source": [
        "print(\"These are the Top 10 companies related to Technological Disruption:\")\n",
        "print(top_10)\n",
        "\n",
        "print(\"\\nThese are the Bottom 10 companies related to Technological Disruption:\")\n",
        "print(bottom_10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMOmtFlTRhu4"
      },
      "source": [
        "<b>Comments on this:</b>\n",
        "- We see pure technological players (what we would expect actually): Nvidia, Synopsis (operating in the semiconductor field)\n",
        "- But we also observe Netflix within the Bottom 10, even though it ictually is related to technological disruption."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VmdtmG-TUxJ"
      },
      "source": [
        "Piste d'amélioration à ce niveau : améliorer la recherche des keywords ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xDMZtqKTogR"
      },
      "outputs": [],
      "source": [
        "# Calculer la similarité cosinus entre la moyenne des vecteurs des mots-clés et tous les mots du modèle\n",
        "def get_most_similar_words_to_avg_vector(model, avg_vector, top_n=10):\n",
        "    similarities = {}\n",
        "    for word in model.index_to_key:  # Iterer sur tous les mots dans le modèle\n",
        "        word_vector = model[word]\n",
        "        similarity = cosine_similarity([avg_vector], [word_vector])[0][0]  # Calculer la similarité cosinus\n",
        "        similarities[word] = similarity\n",
        "\n",
        "    # Trier les mots en fonction de la similarité cosinus et obtenir les 'top_n' mots les plus proches\n",
        "    sorted_similarities = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
        "    return sorted_similarities[:top_n]\n",
        "\n",
        "# Obtenir les 10 mots les plus proches de la moyenne des vecteurs des mots-clés\n",
        "most_similar_words = get_most_similar_words_to_avg_vector(google_model, tech_vectors, top_n=10)\n",
        "\n",
        "# Afficher les mots les plus similaires à la moyenne des mots-clés\n",
        "print(\"Most similar words to the average of technological disruption keywords:\")\n",
        "for word, similarity in most_similar_words:\n",
        "    print(f\"{word}: {similarity}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y205zMIpTpSS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCrRgs9ZTpOm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mTcUJEmTpMQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tV_Kmo0TpEk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMR4KLojl3jO"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ajouter une colonne 'quarter' à partir de la date\n",
        "Pres['quarter'] = pd.to_datetime(Sample_EC['date_rdq']).dt.to_period('Q')\n",
        "\n",
        "# Agréger les scores de disruption technologique par trimestre\n",
        "quarterly_scores = Pres.groupby('quarter')['tech_disruption_score'].mean()\n",
        "\n",
        "# Tracer les résultats\n",
        "plt.figure(figsize=(10, 6))\n",
        "quarterly_scores.plot(kind='line')\n",
        "plt.title(\"Technological Disruption Over Time\")\n",
        "plt.xlabel(\"Quarter\")\n",
        "plt.ylabel(\"Average Technological Disruption Score\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihplJzASI7Ia"
      },
      "outputs": [],
      "source": [
        "# 4. Explorer la réaction du marché (exemple avec des rendements boursiers)\n",
        "# Remplacer par les rendements boursiers réels si disponibles dans le dataset\n",
        "Pres['stock_return'] = Sample_EC['CAR-11-Carhart']  # Exemple d'une variable de rendement\n",
        "\n",
        "# Calculer la corrélation entre les scores de disruption technologique et les rendements boursiers\n",
        "correlation = Pres['tech_disruption_score'].corr(Pres['stock_return'])\n",
        "print(f\"Correlation between tech disruption score and stock return: {correlation}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwPBVbJBJI2e"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# 1. Préparer les données pour la régression\n",
        "# Dépendant : CAR-11-Carhart (rendement boursier, ou autre variable)\n",
        "# Indépendant : tech_disruption_score (score de disruption technologique)\n",
        "\n",
        "# Ajouter les rendements boursiers réels ou toute autre variable financière\n",
        "Pres['stock_return'] = Sample_EC['CAR-11-Carhart']  # Remplacer par les rendements réels si disponibles\n",
        "\n",
        "# Supprimer les valeurs manquantes pour éviter les erreurs dans la régression\n",
        "Pres.dropna(subset=['tech_disruption_score', 'stock_return'], inplace=True)\n",
        "\n",
        "# Variables indépendantes (score de disruption technologique)\n",
        "X = Pres[['tech_disruption_score']]\n",
        "\n",
        "# Variable dépendante (rendement boursier)\n",
        "y = Pres['stock_return']\n",
        "\n",
        "# Ajouter une constante à la matrice des variables indépendantes pour le modèle\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# S'assurer que les indices sont cohérents après suppression des valeurs manquantes\n",
        "y = y.loc[X.index]\n",
        "\n",
        "# Convertir les variables en numériques (si nécessaire)\n",
        "X = X.apply(pd.to_numeric, errors='coerce')\n",
        "y = pd.to_numeric(y, errors='coerce')\n",
        "\n",
        "# 2. Ajuster le modèle de régression (modèle OLS)\n",
        "ols_model = sm.OLS(y, X).fit()\n",
        "\n",
        "# 3. Afficher le résumé de la régression\n",
        "print(ols_model.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jshjZgWfJ7we"
      },
      "outputs": [],
      "source": [
        "# R squared = 0 and non significance..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtnDFlnuLPPN"
      },
      "source": [
        "2 - Using Doc2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "os3oW0JMLTZu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
