{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoWVx_KHwlOq"
      },
      "source": [
        "# __Group Assignment__\n",
        "\n",
        "__Submission Date:__ 26/03/2025\n",
        "\n",
        "__Assignment: NLP-2024-2025: Assignment 1__\n",
        "\n",
        "__Group Members:__\n",
        "- ANZALONE Gabriel\n",
        "- MBENGUE Ndèye Arame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn3nBFurwymC"
      },
      "source": [
        "__Firm level topic of discussion:__ Technological Disruption\n",
        "\n",
        "__Task__ : Measure <u>Technological Disruption</u> with transcripts of Conference Calls."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## __1- Constructing a measure related to <u> Technological Disruption</u> for each firm and each quarter.__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.A- Data Preparation and Text Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyarrow\n",
            "  Downloading pyarrow-19.0.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Downloading pyarrow-19.0.1-cp312-cp312-manylinux_2_28_x86_64.whl (42.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyarrow\n",
            "Successfully installed pyarrow-19.0.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Code for Github\n",
        "!pip install pyarrow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting nltk\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting click (from nltk)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: joblib in /home/codespace/.local/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
            "Collecting regex>=2021.8.3 (from nltk)\n",
            "  Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "Collecting tqdm (from nltk)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Installing collected packages: tqdm, regex, click, nltk\n",
            "Successfully installed click-8.1.8 nltk-3.9.1 regex-2024.11.6 tqdm-4.67.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Code for Github\n",
        "! pip install nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting smart-open>=1.8.1 (from gensim)\n",
            "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
            "  Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Downloading gensim-4.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.6/26.6 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.2/38.2 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
            "Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89 kB)\n",
            "Installing collected packages: wrapt, numpy, smart-open, scipy, gensim\n",
            "Successfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.1.0 wrapt-1.17.2\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Code for Github\n",
        "!pip install gensim\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: setuptools==68.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (68.0.0)\n",
            "Requirement already satisfied: pip in /usr/local/python/3.12.1/lib/python3.12/site-packages (25.0.1)\n",
            "Collecting numpy==1.25.2\n",
            "  Downloading numpy-1.25.2.tar.gz (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m294.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m \u001b[31m[33 lines of output]\u001b[0m\n",
            "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
            "  \u001b[31m   \u001b[0m   File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 389, in <module>\n",
            "  \u001b[31m   \u001b[0m     main()\n",
            "  \u001b[31m   \u001b[0m   File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 373, in main\n",
            "  \u001b[31m   \u001b[0m     json_out[\"return_val\"] = hook(**hook_input[\"kwargs\"])\n",
            "  \u001b[31m   \u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  \u001b[31m   \u001b[0m   File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 137, in get_requires_for_build_wheel\n",
            "  \u001b[31m   \u001b[0m     backend = _build_backend()\n",
            "  \u001b[31m   \u001b[0m               ^^^^^^^^^^^^^^^^\n",
            "  \u001b[31m   \u001b[0m   File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 70, in _build_backend\n",
            "  \u001b[31m   \u001b[0m     obj = import_module(mod_path)\n",
            "  \u001b[31m   \u001b[0m           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  \u001b[31m   \u001b[0m   File \"/usr/local/python/3.12.1/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
            "  \u001b[31m   \u001b[0m     return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
            "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
            "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 1310, in _find_and_load_unlocked\n",
            "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
            "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
            "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
            "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
            "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
            "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap_external>\", line 994, in exec_module\n",
            "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
            "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-x52mgsh3/overlay/lib/python3.12/site-packages/setuptools/__init__.py\", line 16, in <module>\n",
            "  \u001b[31m   \u001b[0m     import setuptools.version\n",
            "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-x52mgsh3/overlay/lib/python3.12/site-packages/setuptools/version.py\", line 1, in <module>\n",
            "  \u001b[31m   \u001b[0m     import pkg_resources\n",
            "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-x52mgsh3/overlay/lib/python3.12/site-packages/pkg_resources/__init__.py\", line 2172, in <module>\n",
            "  \u001b[31m   \u001b[0m     register_finder(pkgutil.ImpImporter, find_on_path)\n",
            "  \u001b[31m   \u001b[0m                     ^^^^^^^^^^^^^^^^^^^\n",
            "  \u001b[31m   \u001b[0m AttributeError: module 'pkgutil' has no attribute 'ImpImporter'. Did you mean: 'zipimporter'?\n",
            "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting smart-open\n",
            "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting numpy<2.5,>=1.23.5 (from scipy)\n",
            "  Downloading numpy-2.2.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/python/3.12.1/lib/python3.12/site-packages (from smart-open) (1.17.2)\n",
            "Downloading scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m280.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
            "Downloading numpy-2.2.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.1/16.1 MB\u001b[0m \u001b[31m561.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: smart-open, numpy, scipy\n",
            "Successfully installed numpy-2.2.4 scipy-1.15.2 smart-open-7.1.0\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/python/3.12.1/lib/python3.12/site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading gensim-4.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.6/26.6 MB\u001b[0m \u001b[31m136.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m743.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.2/38.2 MB\u001b[0m \u001b[31m188.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.4\n",
            "    Uninstalling numpy-2.2.4:\n",
            "      Successfully uninstalled numpy-2.2.4\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.2\n",
            "    Uninstalling scipy-1.15.2:\n",
            "      Successfully uninstalled scipy-1.15.2\n",
            "Successfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"
          ]
        }
      ],
      "source": [
        "# Code for Github\n",
        "!pip install setuptools==68.0.0\n",
        "!pip install --upgrade pip\n",
        "!pip install numpy==1.25.2 --no-cache-dir\n",
        "!pip install scipy smart-open --no-cache-dir\n",
        "!pip install gensim --no-cache-dir\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoKcY7ouyUGg"
      },
      "source": [
        "- Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "dL1uhJxHyY47"
      },
      "outputs": [],
      "source": [
        "# Lets say that we just want to focus on the management presentation section of the Earnings Calls\n",
        "# We import Earnings Calls and Q&A sessions of S&P500 from 2015 to 2021\n",
        "\n",
        "import pandas as pd\n",
        "# Loading Earning calls \n",
        "Sample_EC = pd.read_csv(\"https://www.dropbox.com/scl/fi/2p7ahxroqj9pwf98ni5an/Sample_Calls.csv?rlkey=zfieicvz891u4e3z0aroeg0u7&dl=1\")\n",
        "\n",
        "# Loading Presentations\n",
        "Sample_Presentations = pd.read_feather(\"https://www.dropbox.com/scl/fi/uceh2xva5g4apbmt92cgt/Sample_Calls_Presentations.feather?rlkey=ln4nzsa4nenqyvm0pg2cur9sp&dl=1\")\n",
        "# Loading Q&As\n",
        "Sample_QAs = pd.read_feather(\"https://www.dropbox.com/scl/fi/iq4111nlmsykp2tzxk9xg/Sample_Calls_QA.feather?rlkey=xabjqmwhesx05jivrlfzkgj6m&dl=1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>presentation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...</td>\n",
              "      <td>Good day and welcome to the Linear Technol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...</td>\n",
              "      <td>Welcome to Cerner Corporation's first quar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...</td>\n",
              "      <td>Welcome to Cerner Corporation's second qua...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...</td>\n",
              "      <td>Welcome to Cerner Corporation's third quar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...</td>\n",
              "      <td>Welcome to Cerner Corporation's fourth qua...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           file_name  \\\n",
              "0  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...   \n",
              "1  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...   \n",
              "2  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...   \n",
              "3  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...   \n",
              "4  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...   \n",
              "\n",
              "                                        presentation  \n",
              "0      Good day and welcome to the Linear Technol...  \n",
              "1      Welcome to Cerner Corporation's first quar...  \n",
              "2      Welcome to Cerner Corporation's second qua...  \n",
              "3      Welcome to Cerner Corporation's third quar...  \n",
              "4      Welcome to Cerner Corporation's fourth qua...  "
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Sample_Presentations.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>QA</th>\n",
              "      <th>speaker_name</th>\n",
              "      <th>file_name</th>\n",
              "      <th>QA_text</th>\n",
              "      <th>QA_number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>q</td>\n",
              "      <td>david wong</td>\n",
              "      <td>Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...</td>\n",
              "      <td>Thanks very much. Don, could you give us some ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a</td>\n",
              "      <td>don zerio</td>\n",
              "      <td>Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...</td>\n",
              "      <td>Yes, David, as you know we retired our convert...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>q</td>\n",
              "      <td>david wong</td>\n",
              "      <td>Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...</td>\n",
              "      <td>Great, thanks.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>q</td>\n",
              "      <td>craig hettenbach</td>\n",
              "      <td>Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...</td>\n",
              "      <td>Great thank you. Just a question on the commen...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a</td>\n",
              "      <td>lothar maier</td>\n",
              "      <td>Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...</td>\n",
              "      <td>When you think about China you know, particula...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  QA       speaker_name                                          file_name  \\\n",
              "0  q         david wong  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...   \n",
              "1  a          don zerio  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...   \n",
              "2  q         david wong  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...   \n",
              "3  q   craig hettenbach  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...   \n",
              "4  a       lothar maier  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...   \n",
              "\n",
              "                                             QA_text  QA_number  \n",
              "0  Thanks very much. Don, could you give us some ...          1  \n",
              "1  Yes, David, as you know we retired our convert...          1  \n",
              "2                                     Great, thanks.          2  \n",
              "3  Great thank you. Just a question on the commen...          3  \n",
              "4  When you think about China you know, particula...          3  "
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Sample_QAs.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# filtering for answers only for the Q&A\n",
        "temp = Sample_QAs[Sample_QAs['QA'] == 'a']\n",
        "# Aggregating Answers by file_name\n",
        "temp = temp.groupby('file_name')['QA_text'].apply(lambda x: ' '.join(x)).reset_index()\n",
        "# Merging Back into the Main Dataset\n",
        "Sample_answers = Sample_EC.merge(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GVKEY</th>\n",
              "      <th>date_rdq</th>\n",
              "      <th>co_conm</th>\n",
              "      <th>file_name</th>\n",
              "      <th>CAR-11-Carhart</th>\n",
              "      <th>CAR-11-ff3</th>\n",
              "      <th>CAR01-Carhart</th>\n",
              "      <th>CAR01-ff3</th>\n",
              "      <th>IV</th>\n",
              "      <th>hvol</th>\n",
              "      <th>...</th>\n",
              "      <th>niq</th>\n",
              "      <th>epspxq</th>\n",
              "      <th>epspiq</th>\n",
              "      <th>dlttq</th>\n",
              "      <th>dlcq</th>\n",
              "      <th>prccq</th>\n",
              "      <th>cshoq</th>\n",
              "      <th>dvpq</th>\n",
              "      <th>xintq</th>\n",
              "      <th>QA_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16101.0</td>\n",
              "      <td>2016-07-29 13:00:00+00:00</td>\n",
              "      <td>ABBVIE INC</td>\n",
              "      <td>Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...</td>\n",
              "      <td>0.011886</td>\n",
              "      <td>0.014261</td>\n",
              "      <td>0.014261</td>\n",
              "      <td>0.021246</td>\n",
              "      <td>0.179151</td>\n",
              "      <td>0.129186</td>\n",
              "      <td>...</td>\n",
              "      <td>1610.0</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.99</td>\n",
              "      <td>37328.0</td>\n",
              "      <td>517.0</td>\n",
              "      <td>61.91</td>\n",
              "      <td>1628.542</td>\n",
              "      <td>0.0</td>\n",
              "      <td>245.0</td>\n",
              "      <td>Jeff, this is Rick. I will cover the first and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16101.0</td>\n",
              "      <td>2016-04-28 13:00:00+00:00</td>\n",
              "      <td>ABBVIE INC</td>\n",
              "      <td>Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...</td>\n",
              "      <td>0.026387</td>\n",
              "      <td>0.023499</td>\n",
              "      <td>0.023499</td>\n",
              "      <td>0.021770</td>\n",
              "      <td>0.289777</td>\n",
              "      <td>0.114447</td>\n",
              "      <td>...</td>\n",
              "      <td>1354.0</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0.83</td>\n",
              "      <td>29490.0</td>\n",
              "      <td>2423.0</td>\n",
              "      <td>57.12</td>\n",
              "      <td>1617.359</td>\n",
              "      <td>0.0</td>\n",
              "      <td>215.0</td>\n",
              "      <td>Okay. Hi, Jeff, it's Rick. So I'll take I gues...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16101.0</td>\n",
              "      <td>2016-10-28 13:00:00+00:00</td>\n",
              "      <td>ABBVIE INC</td>\n",
              "      <td>Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...</td>\n",
              "      <td>-0.078668</td>\n",
              "      <td>-0.079290</td>\n",
              "      <td>-0.079290</td>\n",
              "      <td>-0.092594</td>\n",
              "      <td>0.253269</td>\n",
              "      <td>0.381002</td>\n",
              "      <td>...</td>\n",
              "      <td>1598.0</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.97</td>\n",
              "      <td>37284.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>63.07</td>\n",
              "      <td>1624.908</td>\n",
              "      <td>0.0</td>\n",
              "      <td>271.0</td>\n",
              "      <td>Sure, Jami; this is Rick. Thank you for the qu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16101.0</td>\n",
              "      <td>2017-01-27 14:00:00+00:00</td>\n",
              "      <td>ABBVIE INC</td>\n",
              "      <td>Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...</td>\n",
              "      <td>-0.010152</td>\n",
              "      <td>-0.000737</td>\n",
              "      <td>-0.000737</td>\n",
              "      <td>-0.005279</td>\n",
              "      <td>0.182080</td>\n",
              "      <td>0.145941</td>\n",
              "      <td>...</td>\n",
              "      <td>1391.0</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.85</td>\n",
              "      <td>36440.0</td>\n",
              "      <td>402.0</td>\n",
              "      <td>62.62</td>\n",
              "      <td>1592.513</td>\n",
              "      <td>0.0</td>\n",
              "      <td>277.0</td>\n",
              "      <td>Hi, Jami; it's Bill. So on your operating marg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16101.0</td>\n",
              "      <td>2017-04-27 13:00:00+00:00</td>\n",
              "      <td>ABBVIE INC</td>\n",
              "      <td>Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...</td>\n",
              "      <td>0.010397</td>\n",
              "      <td>0.010672</td>\n",
              "      <td>0.010672</td>\n",
              "      <td>0.012819</td>\n",
              "      <td>0.192822</td>\n",
              "      <td>0.112189</td>\n",
              "      <td>...</td>\n",
              "      <td>1711.0</td>\n",
              "      <td>1.07</td>\n",
              "      <td>1.07</td>\n",
              "      <td>36526.0</td>\n",
              "      <td>425.0</td>\n",
              "      <td>65.16</td>\n",
              "      <td>1591.366</td>\n",
              "      <td>0.0</td>\n",
              "      <td>273.0</td>\n",
              "      <td>Yes. Well, first, thanks for the question. May...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2872</th>\n",
              "      <td>189491.0</td>\n",
              "      <td>2016-11-01 13:00:00+00:00</td>\n",
              "      <td>XYLEM INC</td>\n",
              "      <td>Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...</td>\n",
              "      <td>-0.022716</td>\n",
              "      <td>-0.023069</td>\n",
              "      <td>-0.023069</td>\n",
              "      <td>-0.015313</td>\n",
              "      <td>0.238038</td>\n",
              "      <td>0.176583</td>\n",
              "      <td>...</td>\n",
              "      <td>73.0</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.41</td>\n",
              "      <td>1148.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>52.45</td>\n",
              "      <td>179.400</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>Yes, well, thanks for the question, Jim. First...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2873</th>\n",
              "      <td>189491.0</td>\n",
              "      <td>2016-08-02 13:00:00+00:00</td>\n",
              "      <td>XYLEM INC</td>\n",
              "      <td>Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...</td>\n",
              "      <td>-0.036201</td>\n",
              "      <td>-0.034737</td>\n",
              "      <td>-0.034737</td>\n",
              "      <td>-0.037363</td>\n",
              "      <td>0.201698</td>\n",
              "      <td>0.213624</td>\n",
              "      <td>...</td>\n",
              "      <td>71.0</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1143.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>44.65</td>\n",
              "      <td>179.200</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>Sure, Deane. Let me just characterize what we ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2874</th>\n",
              "      <td>189491.0</td>\n",
              "      <td>2020-07-30 13:00:00+00:00</td>\n",
              "      <td>XYLEM INC</td>\n",
              "      <td>Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2020...</td>\n",
              "      <td>-0.030116</td>\n",
              "      <td>-0.028020</td>\n",
              "      <td>-0.028020</td>\n",
              "      <td>-0.049431</td>\n",
              "      <td>0.325614</td>\n",
              "      <td>0.345711</td>\n",
              "      <td>...</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>3031.0</td>\n",
              "      <td>269.0</td>\n",
              "      <td>64.96</td>\n",
              "      <td>180.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>That is correct, Dean, on both counts. Sure. Y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2875</th>\n",
              "      <td>189491.0</td>\n",
              "      <td>2018-05-01 13:00:00+00:00</td>\n",
              "      <td>XYLEM INC</td>\n",
              "      <td>Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2018...</td>\n",
              "      <td>-0.066260</td>\n",
              "      <td>-0.064927</td>\n",
              "      <td>-0.064927</td>\n",
              "      <td>-0.058477</td>\n",
              "      <td>0.206359</td>\n",
              "      <td>0.215869</td>\n",
              "      <td>...</td>\n",
              "      <td>79.0</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.44</td>\n",
              "      <td>2228.0</td>\n",
              "      <td>371.0</td>\n",
              "      <td>76.92</td>\n",
              "      <td>179.500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>Yes, I'll go first here, Nate. And I think the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2876</th>\n",
              "      <td>189491.0</td>\n",
              "      <td>2020-10-29 14:00:00+00:00</td>\n",
              "      <td>XYLEM INC</td>\n",
              "      <td>Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2020...</td>\n",
              "      <td>0.004126</td>\n",
              "      <td>0.003318</td>\n",
              "      <td>0.003318</td>\n",
              "      <td>-0.008976</td>\n",
              "      <td>0.390800</td>\n",
              "      <td>0.153619</td>\n",
              "      <td>...</td>\n",
              "      <td>37.0</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.20</td>\n",
              "      <td>3053.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>84.12</td>\n",
              "      <td>180.100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>Yes. Scott, it's Mark. The price overall for t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2877 rows × 46 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         GVKEY                   date_rdq     co_conm  \\\n",
              "0      16101.0  2016-07-29 13:00:00+00:00  ABBVIE INC   \n",
              "1      16101.0  2016-04-28 13:00:00+00:00  ABBVIE INC   \n",
              "2      16101.0  2016-10-28 13:00:00+00:00  ABBVIE INC   \n",
              "3      16101.0  2017-01-27 14:00:00+00:00  ABBVIE INC   \n",
              "4      16101.0  2017-04-27 13:00:00+00:00  ABBVIE INC   \n",
              "...        ...                        ...         ...   \n",
              "2872  189491.0  2016-11-01 13:00:00+00:00   XYLEM INC   \n",
              "2873  189491.0  2016-08-02 13:00:00+00:00   XYLEM INC   \n",
              "2874  189491.0  2020-07-30 13:00:00+00:00   XYLEM INC   \n",
              "2875  189491.0  2018-05-01 13:00:00+00:00   XYLEM INC   \n",
              "2876  189491.0  2020-10-29 14:00:00+00:00   XYLEM INC   \n",
              "\n",
              "                                              file_name  CAR-11-Carhart  \\\n",
              "0     Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...        0.011886   \n",
              "1     Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...        0.026387   \n",
              "2     Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...       -0.078668   \n",
              "3     Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...       -0.010152   \n",
              "4     Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...        0.010397   \n",
              "...                                                 ...             ...   \n",
              "2872  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...       -0.022716   \n",
              "2873  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...       -0.036201   \n",
              "2874  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2020...       -0.030116   \n",
              "2875  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2018...       -0.066260   \n",
              "2876  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2020...        0.004126   \n",
              "\n",
              "      CAR-11-ff3  CAR01-Carhart  CAR01-ff3        IV      hvol  ...     niq  \\\n",
              "0       0.014261       0.014261   0.021246  0.179151  0.129186  ...  1610.0   \n",
              "1       0.023499       0.023499   0.021770  0.289777  0.114447  ...  1354.0   \n",
              "2      -0.079290      -0.079290  -0.092594  0.253269  0.381002  ...  1598.0   \n",
              "3      -0.000737      -0.000737  -0.005279  0.182080  0.145941  ...  1391.0   \n",
              "4       0.010672       0.010672   0.012819  0.192822  0.112189  ...  1711.0   \n",
              "...          ...            ...        ...       ...       ...  ...     ...   \n",
              "2872   -0.023069      -0.023069  -0.015313  0.238038  0.176583  ...    73.0   \n",
              "2873   -0.034737      -0.034737  -0.037363  0.201698  0.213624  ...    71.0   \n",
              "2874   -0.028020      -0.028020  -0.049431  0.325614  0.345711  ...    31.0   \n",
              "2875   -0.064927      -0.064927  -0.058477  0.206359  0.215869  ...    79.0   \n",
              "2876    0.003318       0.003318  -0.008976  0.390800  0.153619  ...    37.0   \n",
              "\n",
              "      epspxq  epspiq    dlttq    dlcq  prccq     cshoq  dvpq  xintq  \\\n",
              "0       0.99    0.99  37328.0   517.0  61.91  1628.542   0.0  245.0   \n",
              "1       0.83    0.83  29490.0  2423.0  57.12  1617.359   0.0  215.0   \n",
              "2       0.97    0.97  37284.0    26.0  63.07  1624.908   0.0  271.0   \n",
              "3       0.85    0.85  36440.0   402.0  62.62  1592.513   0.0  277.0   \n",
              "4       1.07    1.07  36526.0   425.0  65.16  1591.366   0.0  273.0   \n",
              "...      ...     ...      ...     ...    ...       ...   ...    ...   \n",
              "2872    0.41    0.41   1148.0    62.0  52.45   179.400   0.0   12.0   \n",
              "2873    0.39    0.39   1143.0    91.0  44.65   179.200   0.0   12.0   \n",
              "2874    0.17    0.17   3031.0   269.0  64.96   180.000   0.0   18.0   \n",
              "2875    0.44    0.44   2228.0   371.0  76.92   179.500   0.0   21.0   \n",
              "2876    0.20    0.20   3053.0   101.0  84.12   180.100   0.0   22.0   \n",
              "\n",
              "                                                QA_text  \n",
              "0     Jeff, this is Rick. I will cover the first and...  \n",
              "1     Okay. Hi, Jeff, it's Rick. So I'll take I gues...  \n",
              "2     Sure, Jami; this is Rick. Thank you for the qu...  \n",
              "3     Hi, Jami; it's Bill. So on your operating marg...  \n",
              "4     Yes. Well, first, thanks for the question. May...  \n",
              "...                                                 ...  \n",
              "2872  Yes, well, thanks for the question, Jim. First...  \n",
              "2873  Sure, Deane. Let me just characterize what we ...  \n",
              "2874  That is correct, Dean, on both counts. Sure. Y...  \n",
              "2875  Yes, I'll go first here, Nate. And I think the...  \n",
              "2876  Yes. Scott, it's Mark. The price overall for t...  \n",
              "\n",
              "[2877 rows x 46 columns]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Sample_answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filtering for consistency\n",
        "Sample_Presentations = Sample_Presentations[\n",
        "    Sample_Presentations['presentation'].str.split().apply(len) > 50 # filter to keep presentations with at least 50 words\n",
        "].reset_index(drop=True)\n",
        "\n",
        "# Grouping by file_name and concatenating presentation column (concatenating all text belonging to the same call into one large text entry)\n",
        "Pres = Sample_Presentations.groupby(\"file_name\")[\"presentation\"].agg(lambda x: \" \".join(x)).reset_index()\n",
        "Pres.columns= [\"file_name\",\"text\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_HBmjz9dNpZ"
      },
      "source": [
        "- Prep-processing Textual Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJwMCdV7dMvQ",
        "outputId": "08771f50-11d2-440f-84b6-ce9d9c6002a0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/codespace/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/codespace/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     /home/codespace/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /home/codespace/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# librairies\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize #breaking text into words\n",
        "from nltk.stem import WordNetLemmatizer #reducing words to their base form\n",
        "\n",
        "# Downloading data \n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "HcVD_UxWdUQX"
      },
      "outputs": [],
      "source": [
        "# We first tokenize words & remove the stopwords\n",
        "stop_words = set(stopwords.words('english')) # preprocessing all words, removing the stopwords and using tokenization\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower()) # putting all in lowercase format\n",
        "    tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
        "    return tokens\n",
        "\n",
        "Pres['tokens'] = Pres['text'].apply(preprocess_text)\n",
        "\n",
        "Sample_answers['tokens'] = Sample_answers['QA_text'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "x9nq2CGndXw1"
      },
      "outputs": [],
      "source": [
        "# Then we lemmatize to have a unified format\n",
        "# Either use WordNetLemmatizer or Spacy -> better to use the latter to take the context of each word into account (POS Tagging)\n",
        "# But it is way Longer than WordNet to run\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(tokens):\n",
        "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "Pres['tokens'] = Pres['tokens'].apply(lemmatize_text)\n",
        "\n",
        "Sample_answers['tokens'] = Sample_answers['tokens'].apply(lemmatize_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "EVFT33D0eDHT",
        "outputId": "a56daeec-da7f-40c0-bad1-5e27486105f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    [lady, gentleman, thank, standing, welcome, fi...\n",
              "1    [welcome, prudential, quarterly, earnings, cal...\n",
              "2    [lady, gentleman, thank, standing, welcome, pr...\n",
              "3    [lady, gentleman, thank, standing, welcome, q1...\n",
              "4    [lady, gentleman, thank, standing, welcome, q2...\n",
              "5    [thank, tom, good, morning, everyone, welcome,...\n",
              "6    [welcome, southwest, airline, second, quarter,...\n",
              "7    [thank, tom, good, morning, everyone, welcome,...\n",
              "8    [lady, gentleman, thank, standing, welcome, an...\n",
              "9    [lady, gentleman, thank, standing, welcome, an...\n",
              "Name: tokens, dtype: object"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Pres['tokens'].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    [jeff, rick, cover, first, third, one, mike, c...\n",
              "1    [okay, hi, jeff, rick, take, guess, question, ...\n",
              "2    [sure, jami, rick, thank, question, think, loo...\n",
              "3    [hi, jami, bill, operating, margin, question, ...\n",
              "4    [yes, well, first, thanks, question, maybe, le...\n",
              "5    [okay, jami, thanks, much, question, try, take...\n",
              "6    [okay, mike, maybe, start, talking, rate, cove...\n",
              "7    [right, jami, rick, first, thank, compliment, ...\n",
              "8    [right, thanks, jami, rick, appreciate, questi...\n",
              "9    [rick, take, first, question, mike, cover, sec...\n",
              "Name: tokens, dtype: object"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Sample_answers['tokens'].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yi7ePwBNeDDJ",
        "outputId": "3d65ebcd-858e-4b6e-fc6c-56e3152663eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Pres['text'].isnull().sum() # 0 null value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.int64(0)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Sample_answers['QA_text'].isnull().sum() # 0 null value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guhbcSWxBPbn"
      },
      "source": [
        "### 1.B - Using Cosine Similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0smAxZ8LfeT"
      },
      "source": [
        "- Using Google's Word2Vec API model to find words related to \"technological disruption"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9PIhejul30o"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip uninstall -y numpy gensim scipy smart-open\n",
        "!pip install numpy==1.25.2 scipy==1.10.1 gensim==4.3.0 smart-open\n",
        "# After this, restart the session (restart keernel, don't delete runtime)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dRw4d009-y16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Loading Google's pre-trained Word2Vec model with 300-dimensional vector\n",
        "import gensim.downloader as api\n",
        "google_model = api.load(\"word2vec-google-news-300\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Finding words similar to the key terms to help build a vocabulary related to \"technological disruption\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ienyzD_-BaQw",
        "outputId": "a6a02fdb-3532-459f-df81-8cc38d6897ac"
      },
      "outputs": [],
      "source": [
        "# What we will do is select a bunch of words based on their similarity with Technological Disruption and add them to our tech dictionnary\n",
        "# First using: \"most_similar\" function of google_model\n",
        "# Limit = we can use only one word\n",
        "print(google_model.most_similar(\"technological\", topn=5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQUaut9iDGgW",
        "outputId": "6a801ae5-277a-45c5-9495-8ecfca16a063"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('disruptions', 0.8658042550086975), ('interruption', 0.658836841583252), ('interruptions', 0.6469897627830505), ('distruption', 0.6304445862770081), ('disrupted', 0.6218001842498779)]\n"
          ]
        }
      ],
      "source": [
        "print(google_model.most_similar(\"disruption\", topn=5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DLqImGCDTM_",
        "outputId": "3b4fecd8-03e9-49a9-d92b-5bd0f44e080a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('innovations', 0.7695900797843933), ('technological_advances', 0.7287052869796753), ('technological_advancements', 0.7118793725967407), ('technological_advancement', 0.6809303760528564), ('technologies', 0.6743346452713013)]\n"
          ]
        }
      ],
      "source": [
        "print(google_model.most_similar(\"technological_innovations\", topn=5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eqjmz1EuD6hp"
      },
      "outputs": [],
      "source": [
        "# Lets say we want to create a bag of words that are closely linked to technological disruption:\n",
        "# We can select among these and add our proper words to create a dictionnary:\n",
        "\n",
        "keywords = [\"disruption\",\"technological\",\"interruption\",\"advancement\",\"innovation\",\"ai\",\"automation\", \"robotics\", \"technology\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPU8LF3iMOtP"
      },
      "source": [
        "Computing Cosine Similarity mean of this vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXf1bmJrEYlI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# If we take the mean of all of these keywords in the model, and word with the cosine similarity:\n",
        "tech_vectors = np.mean([google_model[word] for word in keywords if word in google_model], axis=0)\n",
        "\n",
        "def compute_similarity(tokens):\n",
        "    vectors = np.array([google_model[word] for word in tokens if word in google_model])\n",
        "    if vectors.size == 0:\n",
        "        return 0  # Aucun mot trouvé dans le modèle\n",
        "    avg_vector = np.mean(vectors, axis=0)\n",
        "    similarity = cosine_similarity([avg_vector], [tech_vectors])[0][0]\n",
        "    return similarity\n",
        "\n",
        "Pres['tech_disruption_score'] = Pres['tokens'].apply(compute_similarity) # affecting a score to each"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tA70PcuzMrTb"
      },
      "source": [
        "Filtering Companies based on their score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FyW3GwX4Nz1x"
      },
      "outputs": [],
      "source": [
        "Pres = Pres.merge(Sample_EC[['file_name', 'co_conm']], on='file_name', how='left') # we merge the data to get the names of the companies\n",
        "\n",
        "sorted_pres = Pres.sort_values(by='tech_disruption_score', ascending=False) # filtering by the disruption score\n",
        "\n",
        "top_10 = sorted_pres[['file_name', 'co_conm', 'tech_disruption_score']].head(10)\n",
        "bottom_10 = sorted_pres[['file_name', 'co_conm', 'tech_disruption_score']].tail(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRzlGy2PRSf8",
        "outputId": "ae9c68ae-9721-4665-8a72-85c42208c96b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "These are the Top 10 companies related to Technological Disruption:\n",
            "                                              file_name  \\\n",
            "2557  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2020...   \n",
            "1948  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2019...   \n",
            "446   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...   \n",
            "2805  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2020...   \n",
            "2595  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2020...   \n",
            "695   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...   \n",
            "780   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...   \n",
            "1996  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2019...   \n",
            "1464  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2018...   \n",
            "510   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...   \n",
            "\n",
            "                       co_conm  tech_disruption_score  \n",
            "2557               NVIDIA CORP               0.597319  \n",
            "1948                 ANSYS INC               0.596867  \n",
            "446                NVIDIA CORP               0.591857  \n",
            "2805               NVIDIA CORP               0.588900  \n",
            "2595              SYNOPSYS INC               0.588518  \n",
            "695               SYNOPSYS INC               0.587765  \n",
            "780   COGNIZANT TECH SOLUTIONS               0.586810  \n",
            "1996               NVIDIA CORP               0.584074  \n",
            "1464               NVIDIA CORP               0.583366  \n",
            "510   COGNIZANT TECH SOLUTIONS               0.579628  \n",
            "\n",
            "These are the Bottom 10 companies related to Technological Disruption:\n",
            "                                              file_name           co_conm  \\\n",
            "23    Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...   ROSS STORES INC   \n",
            "2787  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2020...     CELANESE CORP   \n",
            "986   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...  WYNN RESORTS LTD   \n",
            "580   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...       NETFLIX INC   \n",
            "600   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...   ROSS STORES INC   \n",
            "1990  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2019...   ROSS STORES INC   \n",
            "1283  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2018...   ROSS STORES INC   \n",
            "1030  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...       NETFLIX INC   \n",
            "184   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...  WYNN RESORTS LTD   \n",
            "880   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...       NETFLIX INC   \n",
            "\n",
            "      tech_disruption_score  \n",
            "23                 0.333194  \n",
            "2787               0.332099  \n",
            "986                0.331706  \n",
            "580                0.328053  \n",
            "600                0.326975  \n",
            "1990               0.326335  \n",
            "1283               0.317994  \n",
            "1030               0.317884  \n",
            "184                0.313835  \n",
            "880                0.293479  \n"
          ]
        }
      ],
      "source": [
        "print(\"These are the Top 10 companies related to Technological Disruption:\")\n",
        "print(top_10)\n",
        "\n",
        "print(\"\\nThese are the Bottom 10 companies related to Technological Disruption:\")\n",
        "print(bottom_10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMOmtFlTRhu4"
      },
      "source": [
        "<b>Comments on this:</b>\n",
        "- We see pure technological players (what we would expect actually): Nvidia, Synopsis (operating in the semiconductor field)\n",
        "- But we also observe Netflix within the Bottom 10, even though it ictually is related to technological disruption."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VmdtmG-TUxJ"
      },
      "source": [
        "Piste d'amélioration à ce niveau : améliorer la recherche des keywords ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xDMZtqKTogR"
      },
      "outputs": [],
      "source": [
        "# Calculer la similarité cosinus entre la moyenne des vecteurs des mots-clés et tous les mots du modèle\n",
        "def get_most_similar_words_to_avg_vector(model, avg_vector, top_n=10):\n",
        "    similarities = {}\n",
        "    for word in model.index_to_key:  # Iterer sur tous les mots dans le modèle\n",
        "        word_vector = model[word]\n",
        "        similarity = cosine_similarity([avg_vector], [word_vector])[0][0]  # Calculer la similarité cosinus\n",
        "        similarities[word] = similarity\n",
        "\n",
        "    # Trier les mots en fonction de la similarité cosinus et obtenir les 'top_n' mots les plus proches\n",
        "    sorted_similarities = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
        "    return sorted_similarities[:top_n]\n",
        "\n",
        "# Obtenir les 10 mots les plus proches de la moyenne des vecteurs des mots-clés\n",
        "most_similar_words = get_most_similar_words_to_avg_vector(google_model, tech_vectors, top_n=10)\n",
        "\n",
        "# Afficher les mots les plus similaires à la moyenne des mots-clés\n",
        "print(\"Most similar words to the average of technological disruption keywords:\")\n",
        "for word, similarity in most_similar_words:\n",
        "    print(f\"{word}: {similarity}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y205zMIpTpSS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCrRgs9ZTpOm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mTcUJEmTpMQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tV_Kmo0TpEk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMR4KLojl3jO"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ajouter une colonne 'quarter' à partir de la date\n",
        "Pres['quarter'] = pd.to_datetime(Sample_EC['date_rdq']).dt.to_period('Q')\n",
        "\n",
        "# Agréger les scores de disruption technologique par trimestre\n",
        "quarterly_scores = Pres.groupby('quarter')['tech_disruption_score'].mean()\n",
        "\n",
        "# Tracer les résultats\n",
        "plt.figure(figsize=(10, 6))\n",
        "quarterly_scores.plot(kind='line')\n",
        "plt.title(\"Technological Disruption Over Time\")\n",
        "plt.xlabel(\"Quarter\")\n",
        "plt.ylabel(\"Average Technological Disruption Score\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihplJzASI7Ia"
      },
      "outputs": [],
      "source": [
        "# 4. Explorer la réaction du marché (exemple avec des rendements boursiers)\n",
        "# Remplacer par les rendements boursiers réels si disponibles dans le dataset\n",
        "Pres['stock_return'] = Sample_EC['CAR-11-Carhart']  # Exemple d'une variable de rendement\n",
        "\n",
        "# Calculer la corrélation entre les scores de disruption technologique et les rendements boursiers\n",
        "correlation = Pres['tech_disruption_score'].corr(Pres['stock_return'])\n",
        "print(f\"Correlation between tech disruption score and stock return: {correlation}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwPBVbJBJI2e"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# 1. Préparer les données pour la régression\n",
        "# Dépendant : CAR-11-Carhart (rendement boursier, ou autre variable)\n",
        "# Indépendant : tech_disruption_score (score de disruption technologique)\n",
        "\n",
        "# Ajouter les rendements boursiers réels ou toute autre variable financière\n",
        "Pres['stock_return'] = Sample_EC['CAR-11-Carhart']  # Remplacer par les rendements réels si disponibles\n",
        "\n",
        "# Supprimer les valeurs manquantes pour éviter les erreurs dans la régression\n",
        "Pres.dropna(subset=['tech_disruption_score', 'stock_return'], inplace=True)\n",
        "\n",
        "# Variables indépendantes (score de disruption technologique)\n",
        "X = Pres[['tech_disruption_score']]\n",
        "\n",
        "# Variable dépendante (rendement boursier)\n",
        "y = Pres['stock_return']\n",
        "\n",
        "# Ajouter une constante à la matrice des variables indépendantes pour le modèle\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# S'assurer que les indices sont cohérents après suppression des valeurs manquantes\n",
        "y = y.loc[X.index]\n",
        "\n",
        "# Convertir les variables en numériques (si nécessaire)\n",
        "X = X.apply(pd.to_numeric, errors='coerce')\n",
        "y = pd.to_numeric(y, errors='coerce')\n",
        "\n",
        "# 2. Ajuster le modèle de régression (modèle OLS)\n",
        "ols_model = sm.OLS(y, X).fit()\n",
        "\n",
        "# 3. Afficher le résumé de la régression\n",
        "print(ols_model.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jshjZgWfJ7we"
      },
      "outputs": [],
      "source": [
        "# R squared = 0 and non significance..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtnDFlnuLPPN"
      },
      "source": [
        "2 - Using Doc2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "os3oW0JMLTZu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
