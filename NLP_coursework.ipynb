{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoWVx_KHwlOq"
      },
      "source": [
        "# __Group Assignment__\n",
        "\n",
        "__Submission Date:__ 26/03/2025\n",
        "\n",
        "__Assignment: NLP-2024-2025: Assignment 1__\n",
        "\n",
        "__Group Members:__\n",
        "- ANZALONE Gabriel\n",
        "- MBENGUE Ndèye Arame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn3nBFurwymC"
      },
      "source": [
        "__Firm level topic of discussion:__ Technological Disruption\n",
        "\n",
        "__Task__ : Measure <u>Technological Disruption</u> with transcripts of Conference Calls."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## __1- Constructing a measure related to <u> Technological Disruption</u> for each firm and each quarter.__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.A- Data Import and Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoKcY7ouyUGg"
      },
      "source": [
        "Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dL1uhJxHyY47"
      },
      "outputs": [],
      "source": [
        "# Lets say that we just want to focus on the management presentation section of the Earnings Calls\n",
        "# We import Earnings Calls of S&P500 from 2015 to 2021\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "Sample_EC = pd.read_csv(\"https://www.dropbox.com/scl/fi/2p7ahxroqj9pwf98ni5an/Sample_Calls.csv?rlkey=zfieicvz891u4e3z0aroeg0u7&dl=1\")\n",
        "Sample_Presentations = pd.read_feather(\"https://www.dropbox.com/scl/fi/uceh2xva5g4apbmt92cgt/Sample_Calls_Presentations.feather?rlkey=ln4nzsa4nenqyvm0pg2cur9sp&dl=1\")\n",
        "\n",
        "Sample_Presentations = Sample_Presentations[\n",
        "    Sample_Presentations['presentation'].str.split().apply(len) > 50 # filter to keep presentations with at least 50 words\n",
        "].reset_index(drop=True)\n",
        "\n",
        "# Group by file_name and concatenate presentation column\n",
        "Pres = Sample_Presentations.groupby(\"file_name\")[\"presentation\"].agg(lambda x: \" \".join(x)).reset_index()\n",
        "Pres.columns= [\"file_name\",\"text\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_HBmjz9dNpZ"
      },
      "source": [
        "Prepprocessing the text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJwMCdV7dMvQ",
        "outputId": "08771f50-11d2-440f-84b6-ce9d9c6002a0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcVD_UxWdUQX"
      },
      "outputs": [],
      "source": [
        "# We first tokenize words & remove the stopwords\n",
        "stop_words = set(stopwords.words('english')) # preprocessing all words, removing the stopwords and using tokenization\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower()) # putting all in lowercase format\n",
        "    tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
        "    return tokens\n",
        "\n",
        "Pres['tokens'] = Pres['text'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9nq2CGndXw1"
      },
      "outputs": [],
      "source": [
        "# Then we lemmatize to have a unified format\n",
        "# Either use WordNetLemmatizer or Spacy -> better to use the latter to take the context of each word into account (POS Tagging)\n",
        "# But it is way Longer than WordNet to run\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(tokens):\n",
        "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "Pres['tokens'] = Pres['tokens'].apply(lemmatize_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "EVFT33D0eDHT",
        "outputId": "a56daeec-da7f-40c0-bad1-5e27486105f4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[lady, gentleman, thank, standing, welcome, fi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[welcome, prudential, quarterly, earnings, cal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[lady, gentleman, thank, standing, welcome, pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[lady, gentleman, thank, standing, welcome, q1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[lady, gentleman, thank, standing, welcome, q2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[thank, tom, good, morning, everyone, welcome,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[welcome, southwest, airline, second, quarter,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[thank, tom, good, morning, everyone, welcome,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[lady, gentleman, thank, standing, welcome, an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[lady, gentleman, thank, standing, welcome, an...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "0    [lady, gentleman, thank, standing, welcome, fi...\n",
              "1    [welcome, prudential, quarterly, earnings, cal...\n",
              "2    [lady, gentleman, thank, standing, welcome, pr...\n",
              "3    [lady, gentleman, thank, standing, welcome, q1...\n",
              "4    [lady, gentleman, thank, standing, welcome, q2...\n",
              "5    [thank, tom, good, morning, everyone, welcome,...\n",
              "6    [welcome, southwest, airline, second, quarter,...\n",
              "7    [thank, tom, good, morning, everyone, welcome,...\n",
              "8    [lady, gentleman, thank, standing, welcome, an...\n",
              "9    [lady, gentleman, thank, standing, welcome, an...\n",
              "Name: tokens, dtype: object"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Pres['tokens'].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yi7ePwBNeDDJ",
        "outputId": "3d65ebcd-858e-4b6e-fc6c-56e3152663eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Pres['text'].isnull().sum() # 0 null value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guhbcSWxBPbn"
      },
      "source": [
        "### 1 - Using Cosine Similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0smAxZ8LfeT"
      },
      "source": [
        "Working with Google Word2Vec API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9PIhejul30o"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip uninstall -y numpy gensim scipy smart-open\n",
        "!pip install numpy==1.25.2 scipy gensim smart-open\n",
        "# After this, restart session (don't delete runtime)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRw4d009-y16"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api\n",
        "google_model = api.load(\"word2vec-google-news-300\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ienyzD_-BaQw",
        "outputId": "a6a02fdb-3532-459f-df81-8cc38d6897ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('technological_advancement', 0.6745783090591431), ('technological_advances', 0.6342653036117554), ('technological_innovations', 0.6328529715538025), ('technologic', 0.6312510967254639), ('DISABILITY_RESOURCE_CENTER', 0.6264010667800903)]\n"
          ]
        }
      ],
      "source": [
        "# What we will do is select a bunch of words based on their similarity with Technological Disruption and add them to our tech dictionnary\n",
        "# First using: \"most_similar\" function of google_model\n",
        "# Limit = we can use only one word\n",
        "print(google_model.most_similar(\"technological\", topn=5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQUaut9iDGgW",
        "outputId": "6a801ae5-277a-45c5-9495-8ecfca16a063"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('disruptions', 0.8658042550086975), ('interruption', 0.658836841583252), ('interruptions', 0.6469897627830505), ('distruption', 0.6304445862770081), ('disrupted', 0.6218001842498779)]\n"
          ]
        }
      ],
      "source": [
        "print(google_model.most_similar(\"disruption\", topn=5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DLqImGCDTM_",
        "outputId": "3b4fecd8-03e9-49a9-d92b-5bd0f44e080a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('innovations', 0.7695900797843933), ('technological_advances', 0.7287052869796753), ('technological_advancements', 0.7118793725967407), ('technological_advancement', 0.6809303760528564), ('technologies', 0.6743346452713013)]\n"
          ]
        }
      ],
      "source": [
        "print(google_model.most_similar(\"technological_innovations\", topn=5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eqjmz1EuD6hp"
      },
      "outputs": [],
      "source": [
        "# Lets say we want to create a bag of words that are closely linked to technological disruption:\n",
        "# We can select among these and add our proper words to create a dictionnary:\n",
        "\n",
        "keywords = [\"disruption\",\"technological\",\"interruption\",\"advancement\",\"innovation\",\"ai\",\"automation\", \"robotics\", \"technology\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPU8LF3iMOtP"
      },
      "source": [
        "Computing Cosine Similarity mean of this vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXf1bmJrEYlI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# If we take the mean of all of these keywords in the model, and word with the cosine similarity:\n",
        "tech_vectors = np.mean([google_model[word] for word in keywords if word in google_model], axis=0)\n",
        "\n",
        "def compute_similarity(tokens):\n",
        "    vectors = np.array([google_model[word] for word in tokens if word in google_model])\n",
        "    if vectors.size == 0:\n",
        "        return 0  # Aucun mot trouvé dans le modèle\n",
        "    avg_vector = np.mean(vectors, axis=0)\n",
        "    similarity = cosine_similarity([avg_vector], [tech_vectors])[0][0]\n",
        "    return similarity\n",
        "\n",
        "Pres['tech_disruption_score'] = Pres['tokens'].apply(compute_similarity) # affecting a score to each"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tA70PcuzMrTb"
      },
      "source": [
        "Filtering Companies based on their score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FyW3GwX4Nz1x"
      },
      "outputs": [],
      "source": [
        "Pres = Pres.merge(Sample_EC[['file_name', 'co_conm']], on='file_name', how='left') # we merge the data to get the names of the companies\n",
        "\n",
        "sorted_pres = Pres.sort_values(by='tech_disruption_score', ascending=False) # filtering by the disruption score\n",
        "\n",
        "top_10 = sorted_pres[['file_name', 'co_conm', 'tech_disruption_score']].head(10)\n",
        "bottom_10 = sorted_pres[['file_name', 'co_conm', 'tech_disruption_score']].tail(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRzlGy2PRSf8",
        "outputId": "ae9c68ae-9721-4665-8a72-85c42208c96b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "These are the Top 10 companies related to Technological Disruption:\n",
            "                                              file_name  \\\n",
            "2557  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2020...   \n",
            "1948  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2019...   \n",
            "446   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...   \n",
            "2805  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2020...   \n",
            "2595  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2020...   \n",
            "695   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...   \n",
            "780   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...   \n",
            "1996  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2019...   \n",
            "1464  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2018...   \n",
            "510   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...   \n",
            "\n",
            "                       co_conm  tech_disruption_score  \n",
            "2557               NVIDIA CORP               0.597319  \n",
            "1948                 ANSYS INC               0.596867  \n",
            "446                NVIDIA CORP               0.591857  \n",
            "2805               NVIDIA CORP               0.588900  \n",
            "2595              SYNOPSYS INC               0.588518  \n",
            "695               SYNOPSYS INC               0.587765  \n",
            "780   COGNIZANT TECH SOLUTIONS               0.586810  \n",
            "1996               NVIDIA CORP               0.584074  \n",
            "1464               NVIDIA CORP               0.583366  \n",
            "510   COGNIZANT TECH SOLUTIONS               0.579628  \n",
            "\n",
            "These are the Bottom 10 companies related to Technological Disruption:\n",
            "                                              file_name           co_conm  \\\n",
            "23    Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...   ROSS STORES INC   \n",
            "2787  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2020...     CELANESE CORP   \n",
            "986   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...  WYNN RESORTS LTD   \n",
            "580   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...       NETFLIX INC   \n",
            "600   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...   ROSS STORES INC   \n",
            "1990  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2019...   ROSS STORES INC   \n",
            "1283  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2018...   ROSS STORES INC   \n",
            "1030  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...       NETFLIX INC   \n",
            "184   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...  WYNN RESORTS LTD   \n",
            "880   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...       NETFLIX INC   \n",
            "\n",
            "      tech_disruption_score  \n",
            "23                 0.333194  \n",
            "2787               0.332099  \n",
            "986                0.331706  \n",
            "580                0.328053  \n",
            "600                0.326975  \n",
            "1990               0.326335  \n",
            "1283               0.317994  \n",
            "1030               0.317884  \n",
            "184                0.313835  \n",
            "880                0.293479  \n"
          ]
        }
      ],
      "source": [
        "print(\"These are the Top 10 companies related to Technological Disruption:\")\n",
        "print(top_10)\n",
        "\n",
        "print(\"\\nThese are the Bottom 10 companies related to Technological Disruption:\")\n",
        "print(bottom_10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMOmtFlTRhu4"
      },
      "source": [
        "<b>Comments on this:</b>\n",
        "- We see pure technological players (what we would expect actually): Nvidia, Synopsis (operating in the semiconductor field)\n",
        "- But we also observe Netflix within the Bottom 10, even though it ictually is related to technological disruption."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VmdtmG-TUxJ"
      },
      "source": [
        "Piste d'amélioration à ce niveau : améliorer la recherche des keywords ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xDMZtqKTogR"
      },
      "outputs": [],
      "source": [
        "# Calculer la similarité cosinus entre la moyenne des vecteurs des mots-clés et tous les mots du modèle\n",
        "def get_most_similar_words_to_avg_vector(model, avg_vector, top_n=10):\n",
        "    similarities = {}\n",
        "    for word in model.index_to_key:  # Iterer sur tous les mots dans le modèle\n",
        "        word_vector = model[word]\n",
        "        similarity = cosine_similarity([avg_vector], [word_vector])[0][0]  # Calculer la similarité cosinus\n",
        "        similarities[word] = similarity\n",
        "\n",
        "    # Trier les mots en fonction de la similarité cosinus et obtenir les 'top_n' mots les plus proches\n",
        "    sorted_similarities = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
        "    return sorted_similarities[:top_n]\n",
        "\n",
        "# Obtenir les 10 mots les plus proches de la moyenne des vecteurs des mots-clés\n",
        "most_similar_words = get_most_similar_words_to_avg_vector(google_model, tech_vectors, top_n=10)\n",
        "\n",
        "# Afficher les mots les plus similaires à la moyenne des mots-clés\n",
        "print(\"Most similar words to the average of technological disruption keywords:\")\n",
        "for word, similarity in most_similar_words:\n",
        "    print(f\"{word}: {similarity}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y205zMIpTpSS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCrRgs9ZTpOm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mTcUJEmTpMQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tV_Kmo0TpEk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMR4KLojl3jO"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ajouter une colonne 'quarter' à partir de la date\n",
        "Pres['quarter'] = pd.to_datetime(Sample_EC['date_rdq']).dt.to_period('Q')\n",
        "\n",
        "# Agréger les scores de disruption technologique par trimestre\n",
        "quarterly_scores = Pres.groupby('quarter')['tech_disruption_score'].mean()\n",
        "\n",
        "# Tracer les résultats\n",
        "plt.figure(figsize=(10, 6))\n",
        "quarterly_scores.plot(kind='line')\n",
        "plt.title(\"Technological Disruption Over Time\")\n",
        "plt.xlabel(\"Quarter\")\n",
        "plt.ylabel(\"Average Technological Disruption Score\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihplJzASI7Ia"
      },
      "outputs": [],
      "source": [
        "# 4. Explorer la réaction du marché (exemple avec des rendements boursiers)\n",
        "# Remplacer par les rendements boursiers réels si disponibles dans le dataset\n",
        "Pres['stock_return'] = Sample_EC['CAR-11-Carhart']  # Exemple d'une variable de rendement\n",
        "\n",
        "# Calculer la corrélation entre les scores de disruption technologique et les rendements boursiers\n",
        "correlation = Pres['tech_disruption_score'].corr(Pres['stock_return'])\n",
        "print(f\"Correlation between tech disruption score and stock return: {correlation}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwPBVbJBJI2e"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# 1. Préparer les données pour la régression\n",
        "# Dépendant : CAR-11-Carhart (rendement boursier, ou autre variable)\n",
        "# Indépendant : tech_disruption_score (score de disruption technologique)\n",
        "\n",
        "# Ajouter les rendements boursiers réels ou toute autre variable financière\n",
        "Pres['stock_return'] = Sample_EC['CAR-11-Carhart']  # Remplacer par les rendements réels si disponibles\n",
        "\n",
        "# Supprimer les valeurs manquantes pour éviter les erreurs dans la régression\n",
        "Pres.dropna(subset=['tech_disruption_score', 'stock_return'], inplace=True)\n",
        "\n",
        "# Variables indépendantes (score de disruption technologique)\n",
        "X = Pres[['tech_disruption_score']]\n",
        "\n",
        "# Variable dépendante (rendement boursier)\n",
        "y = Pres['stock_return']\n",
        "\n",
        "# Ajouter une constante à la matrice des variables indépendantes pour le modèle\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# S'assurer que les indices sont cohérents après suppression des valeurs manquantes\n",
        "y = y.loc[X.index]\n",
        "\n",
        "# Convertir les variables en numériques (si nécessaire)\n",
        "X = X.apply(pd.to_numeric, errors='coerce')\n",
        "y = pd.to_numeric(y, errors='coerce')\n",
        "\n",
        "# 2. Ajuster le modèle de régression (modèle OLS)\n",
        "ols_model = sm.OLS(y, X).fit()\n",
        "\n",
        "# 3. Afficher le résumé de la régression\n",
        "print(ols_model.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jshjZgWfJ7we"
      },
      "outputs": [],
      "source": [
        "# R squared = 0 and non significance..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtnDFlnuLPPN"
      },
      "source": [
        "2 - Using Doc2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "os3oW0JMLTZu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
