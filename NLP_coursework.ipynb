{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoWVx_KHwlOq"
      },
      "source": [
        "# __Group Assignment__\n",
        "\n",
        "__Submission Date:__ 26/03/2025\n",
        "\n",
        "__Assignment: NLP-2024-2025: Assignment 1__\n",
        "\n",
        "__Group Members:__\n",
        "- ANZALONE Gabriel\n",
        "- MBENGUE Nd√®ye Arame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn3nBFurwymC"
      },
      "source": [
        "__Firm level topic of discussion:__ Technological Disruption\n",
        "\n",
        "__Task__ : Measure <u>Technological Disruption</u> with transcripts of Conference Calls."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## __1- Constructing a measure related to <u> Technological Disruption</u> for each firm and each quarter.__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.A- Data Import and Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoKcY7ouyUGg"
      },
      "source": [
        "Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dL1uhJxHyY47"
      },
      "outputs": [],
      "source": [
        "# Lets say that we just want to focus on the management presentation section of the Earnings Calls\n",
        "# We import Earnings Calls of S&P500 from 2015 to 2021\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "Sample_EC = pd.read_csv(\"https://www.dropbox.com/scl/fi/2p7ahxroqj9pwf98ni5an/Sample_Calls.csv?rlkey=zfieicvz891u4e3z0aroeg0u7&dl=1\")\n",
        "Sample_Presentations = pd.read_feather(\"https://www.dropbox.com/scl/fi/uceh2xva5g4apbmt92cgt/Sample_Calls_Presentations.feather?rlkey=ln4nzsa4nenqyvm0pg2cur9sp&dl=1\")\n",
        "\n",
        "Sample_Presentations = Sample_Presentations[\n",
        "    Sample_Presentations['presentation'].str.split().apply(len) > 50 # filter to keep presentations with at least 50 words\n",
        "].reset_index(drop=True)\n",
        "\n",
        "# Group by file_name and concatenate presentation column\n",
        "Pres = Sample_Presentations.groupby(\"file_name\")[\"presentation\"].agg(lambda x: \" \".join(x)).reset_index()\n",
        "Pres.columns= [\"file_name\",\"text\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_HBmjz9dNpZ"
      },
      "source": [
        "Prepprocessing the text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJwMCdV7dMvQ",
        "outputId": "08771f50-11d2-440f-84b6-ce9d9c6002a0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcVD_UxWdUQX"
      },
      "outputs": [],
      "source": [
        "# We first tokenize words & remove the stopwords\n",
        "stop_words = set(stopwords.words('english')) # preprocessing all words, removing the stopwords and using tokenization\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower()) # putting all in lowercase format\n",
        "    tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
        "    return tokens\n",
        "\n",
        "Pres['tokens'] = Pres['text'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9nq2CGndXw1"
      },
      "outputs": [],
      "source": [
        "# Then we lemmatize to have a unified format\n",
        "# Either use WordNetLemmatizer or Spacy -> better to use the latter to take the context of each word into account (POS Tagging)\n",
        "# But it is way Longer than WordNet to run\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(tokens):\n",
        "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "Pres['tokens'] = Pres['tokens'].apply(lemmatize_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "EVFT33D0eDHT",
        "outputId": "a56daeec-da7f-40c0-bad1-5e27486105f4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[lady, gentleman, thank, standing, welcome, fi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[welcome, prudential, quarterly, earnings, cal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[lady, gentleman, thank, standing, welcome, pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[lady, gentleman, thank, standing, welcome, q1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[lady, gentleman, thank, standing, welcome, q2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[thank, tom, good, morning, everyone, welcome,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[welcome, southwest, airline, second, quarter,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[thank, tom, good, morning, everyone, welcome,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[lady, gentleman, thank, standing, welcome, an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[lady, gentleman, thank, standing, welcome, an...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "0    [lady, gentleman, thank, standing, welcome, fi...\n",
              "1    [welcome, prudential, quarterly, earnings, cal...\n",
              "2    [lady, gentleman, thank, standing, welcome, pr...\n",
              "3    [lady, gentleman, thank, standing, welcome, q1...\n",
              "4    [lady, gentleman, thank, standing, welcome, q2...\n",
              "5    [thank, tom, good, morning, everyone, welcome,...\n",
              "6    [welcome, southwest, airline, second, quarter,...\n",
              "7    [thank, tom, good, morning, everyone, welcome,...\n",
              "8    [lady, gentleman, thank, standing, welcome, an...\n",
              "9    [lady, gentleman, thank, standing, welcome, an...\n",
              "Name: tokens, dtype: object"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Pres['tokens'].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yi7ePwBNeDDJ",
        "outputId": "3d65ebcd-858e-4b6e-fc6c-56e3152663eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Pres['text'].isnull().sum() # 0 null value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guhbcSWxBPbn"
      },
      "source": [
        "### 1 - Using Cosine Similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0smAxZ8LfeT"
      },
      "source": [
        "Working with Google Word2Vec API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9PIhejul30o"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip uninstall -y numpy gensim scipy smart-open\n",
        "!pip install numpy==1.25.2 scipy gensim smart-open\n",
        "# After this, restart session (don't delete runtime)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRw4d009-y16"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api\n",
        "google_model = api.load(\"word2vec-google-news-300\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ienyzD_-BaQw",
        "outputId": "a6a02fdb-3532-459f-df81-8cc38d6897ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('technological_advancement', 0.6745783090591431), ('technological_advances', 0.6342653036117554), ('technological_innovations', 0.6328529715538025), ('technologic', 0.6312510967254639), ('DISABILITY_RESOURCE_CENTER', 0.6264010667800903)]\n"
          ]
        }
      ],
      "source": [
        "# What we will do is select a bunch of words based on their similarity with Technological Disruption and add them to our tech dictionnary\n",
        "# First using: \"most_similar\" function of google_model\n",
        "# Limit = we can use only one word\n",
        "print(google_model.most_similar(\"technological\", topn=5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQUaut9iDGgW",
        "outputId": "6a801ae5-277a-45c5-9495-8ecfca16a063"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('disruptions', 0.8658042550086975), ('interruption', 0.658836841583252), ('interruptions', 0.6469897627830505), ('distruption', 0.6304445862770081), ('disrupted', 0.6218001842498779)]\n"
          ]
        }
      ],
      "source": [
        "print(google_model.most_similar(\"disruption\", topn=5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DLqImGCDTM_",
        "outputId": "3b4fecd8-03e9-49a9-d92b-5bd0f44e080a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('innovations', 0.7695900797843933), ('technological_advances', 0.7287052869796753), ('technological_advancements', 0.7118793725967407), ('technological_advancement', 0.6809303760528564), ('technologies', 0.6743346452713013)]\n"
          ]
        }
      ],
      "source": [
        "print(google_model.most_similar(\"technological_innovations\", topn=5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eqjmz1EuD6hp"
      },
      "outputs": [],
      "source": [
        "# Lets say we want to create a bag of words that are closely linked to technological disruption:\n",
        "# We can select among these and add our proper words to create a dictionnary:\n",
        "\n",
        "keywords = [\"disruption\",\"technological\",\"interruption\",\"advancement\",\"innovation\",\"ai\",\"automation\", \"robotics\", \"technology\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPU8LF3iMOtP"
      },
      "source": [
        "Computing Cosine Similarity mean of this vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXf1bmJrEYlI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# If we take the mean of all of these keywords in the model, and word with the cosine similarity:\n",
        "tech_vectors = np.mean([google_model[word] for word in keywords if word in google_model], axis=0)\n",
        "\n",
        "def compute_similarity(tokens):\n",
        "    vectors = np.array([google_model[word] for word in tokens if word in google_model])\n",
        "    if vectors.size == 0:\n",
        "        return 0  # Aucun mot trouv√© dans le mod√®le\n",
        "    avg_vector = np.mean(vectors, axis=0)\n",
        "    similarity = cosine_similarity([avg_vector], [tech_vectors])[0][0]\n",
        "    return similarity\n",
        "\n",
        "Pres['tech_disruption_score'] = Pres['tokens'].apply(compute_similarity) # affecting a score to each"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tA70PcuzMrTb"
      },
      "source": [
        "Filtering Companies based on their score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FyW3GwX4Nz1x"
      },
      "outputs": [],
      "source": [
        "Pres = Pres.merge(Sample_EC[['file_name', 'co_conm']], on='file_name', how='left') # we merge the data to get the names of the companies\n",
        "\n",
        "sorted_pres = Pres.sort_values(by='tech_disruption_score', ascending=False) # filtering by the disruption score\n",
        "\n",
        "top_10 = sorted_pres[['file_name', 'co_conm', 'tech_disruption_score']].head(10)\n",
        "bottom_10 = sorted_pres[['file_name', 'co_conm', 'tech_disruption_score']].tail(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRzlGy2PRSf8",
        "outputId": "ae9c68ae-9721-4665-8a72-85c42208c96b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "These are the Top 10 companies related to Technological Disruption:\n",
            "                                              file_name  \\\n",
            "2557  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2020...   \n",
            "1948  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2019...   \n",
            "446   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...   \n",
            "2805  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2020...   \n",
            "2595  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2020...   \n",
            "695   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...   \n",
            "780   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...   \n",
            "1996  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2019...   \n",
            "1464  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2018...   \n",
            "510   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...   \n",
            "\n",
            "                       co_conm  tech_disruption_score  \n",
            "2557               NVIDIA CORP               0.597319  \n",
            "1948                 ANSYS INC               0.596867  \n",
            "446                NVIDIA CORP               0.591857  \n",
            "2805               NVIDIA CORP               0.588900  \n",
            "2595              SYNOPSYS INC               0.588518  \n",
            "695               SYNOPSYS INC               0.587765  \n",
            "780   COGNIZANT TECH SOLUTIONS               0.586810  \n",
            "1996               NVIDIA CORP               0.584074  \n",
            "1464               NVIDIA CORP               0.583366  \n",
            "510   COGNIZANT TECH SOLUTIONS               0.579628  \n",
            "\n",
            "These are the Bottom 10 companies related to Technological Disruption:\n",
            "                                              file_name           co_conm  \\\n",
            "23    Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...   ROSS STORES INC   \n",
            "2787  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2020...     CELANESE CORP   \n",
            "986   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...  WYNN RESORTS LTD   \n",
            "580   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...       NETFLIX INC   \n",
            "600   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...   ROSS STORES INC   \n",
            "1990  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2019...   ROSS STORES INC   \n",
            "1283  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2018...   ROSS STORES INC   \n",
            "1030  Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...       NETFLIX INC   \n",
            "184   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2016...  WYNN RESORTS LTD   \n",
            "880   Download ECC/SE/TRANSCRIPT/XMLStd/Archive/2017...       NETFLIX INC   \n",
            "\n",
            "      tech_disruption_score  \n",
            "23                 0.333194  \n",
            "2787               0.332099  \n",
            "986                0.331706  \n",
            "580                0.328053  \n",
            "600                0.326975  \n",
            "1990               0.326335  \n",
            "1283               0.317994  \n",
            "1030               0.317884  \n",
            "184                0.313835  \n",
            "880                0.293479  \n"
          ]
        }
      ],
      "source": [
        "print(\"These are the Top 10 companies related to Technological Disruption:\")\n",
        "print(top_10)\n",
        "\n",
        "print(\"\\nThese are the Bottom 10 companies related to Technological Disruption:\")\n",
        "print(bottom_10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMOmtFlTRhu4"
      },
      "source": [
        "<b>Comments on this:</b>\n",
        "- We see pure technological players (what we would expect actually): Nvidia, Synopsis (operating in the semiconductor field)\n",
        "- But we also observe Netflix within the Bottom 10, even though it ictually is related to technological disruption."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VmdtmG-TUxJ"
      },
      "source": [
        "Piste d'am√©lioration √† ce niveau : am√©liorer la recherche des keywords ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xDMZtqKTogR"
      },
      "outputs": [],
      "source": [
        "# Calculer la similarit√© cosinus entre la moyenne des vecteurs des mots-cl√©s et tous les mots du mod√®le\n",
        "def get_most_similar_words_to_avg_vector(model, avg_vector, top_n=10):\n",
        "    similarities = {}\n",
        "    for word in model.index_to_key:  # Iterer sur tous les mots dans le mod√®le\n",
        "        word_vector = model[word]\n",
        "        similarity = cosine_similarity([avg_vector], [word_vector])[0][0]  # Calculer la similarit√© cosinus\n",
        "        similarities[word] = similarity\n",
        "\n",
        "    # Trier les mots en fonction de la similarit√© cosinus et obtenir les 'top_n' mots les plus proches\n",
        "    sorted_similarities = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
        "    return sorted_similarities[:top_n]\n",
        "\n",
        "# Obtenir les 10 mots les plus proches de la moyenne des vecteurs des mots-cl√©s\n",
        "most_similar_words = get_most_similar_words_to_avg_vector(google_model, tech_vectors, top_n=10)\n",
        "\n",
        "# Afficher les mots les plus similaires √† la moyenne des mots-cl√©s\n",
        "print(\"Most similar words to the average of technological disruption keywords:\")\n",
        "for word, similarity in most_similar_words:\n",
        "    print(f\"{word}: {similarity}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y205zMIpTpSS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCrRgs9ZTpOm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mTcUJEmTpMQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tV_Kmo0TpEk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMR4KLojl3jO"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ajouter une colonne 'quarter' √† partir de la date\n",
        "Pres['quarter'] = pd.to_datetime(Sample_EC['date_rdq']).dt.to_period('Q')\n",
        "\n",
        "# Agr√©ger les scores de disruption technologique par trimestre\n",
        "quarterly_scores = Pres.groupby('quarter')['tech_disruption_score'].mean()\n",
        "\n",
        "# Tracer les r√©sultats\n",
        "plt.figure(figsize=(10, 6))\n",
        "quarterly_scores.plot(kind='line')\n",
        "plt.title(\"Technological Disruption Over Time\")\n",
        "plt.xlabel(\"Quarter\")\n",
        "plt.ylabel(\"Average Technological Disruption Score\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihplJzASI7Ia"
      },
      "outputs": [],
      "source": [
        "# 4. Explorer la r√©action du march√© (exemple avec des rendements boursiers)\n",
        "# Remplacer par les rendements boursiers r√©els si disponibles dans le dataset\n",
        "Pres['stock_return'] = Sample_EC['CAR-11-Carhart']  # Exemple d'une variable de rendement\n",
        "\n",
        "# Calculer la corr√©lation entre les scores de disruption technologique et les rendements boursiers\n",
        "correlation = Pres['tech_disruption_score'].corr(Pres['stock_return'])\n",
        "print(f\"Correlation between tech disruption score and stock return: {correlation}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwPBVbJBJI2e"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# 1. Pr√©parer les donn√©es pour la r√©gression\n",
        "# D√©pendant : CAR-11-Carhart (rendement boursier, ou autre variable)\n",
        "# Ind√©pendant : tech_disruption_score (score de disruption technologique)\n",
        "\n",
        "# Ajouter les rendements boursiers r√©els ou toute autre variable financi√®re\n",
        "Pres['stock_return'] = Sample_EC['CAR-11-Carhart']  # Remplacer par les rendements r√©els si disponibles\n",
        "\n",
        "# Supprimer les valeurs manquantes pour √©viter les erreurs dans la r√©gression\n",
        "Pres.dropna(subset=['tech_disruption_score', 'stock_return'], inplace=True)\n",
        "\n",
        "# Variables ind√©pendantes (score de disruption technologique)\n",
        "X = Pres[['tech_disruption_score']]\n",
        "\n",
        "# Variable d√©pendante (rendement boursier)\n",
        "y = Pres['stock_return']\n",
        "\n",
        "# Ajouter une constante √† la matrice des variables ind√©pendantes pour le mod√®le\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# S'assurer que les indices sont coh√©rents apr√®s suppression des valeurs manquantes\n",
        "y = y.loc[X.index]\n",
        "\n",
        "# Convertir les variables en num√©riques (si n√©cessaire)\n",
        "X = X.apply(pd.to_numeric, errors='coerce')\n",
        "y = pd.to_numeric(y, errors='coerce')\n",
        "\n",
        "# 2. Ajuster le mod√®le de r√©gression (mod√®le OLS)\n",
        "ols_model = sm.OLS(y, X).fit()\n",
        "\n",
        "# 3. Afficher le r√©sum√© de la r√©gression\n",
        "print(ols_model.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jshjZgWfJ7we"
      },
      "outputs": [],
      "source": [
        "# R squared = 0 and non significance..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtnDFlnuLPPN"
      },
      "source": [
        "2 - Using Doc2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "os3oW0JMLTZu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
